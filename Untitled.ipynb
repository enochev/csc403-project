{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 504, 504])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    transform =transforms.Compose([\n",
    "                    #transforms.RandomResizedCrop(128),\n",
    "                    transforms.ToTensor()])\n",
    "    train_set = datasets.ImageFolder('train', transform=transform)\n",
    "    print(train_set[0][0].shape)\n",
    "    train = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    return train\n",
    "\n",
    "train = get_data()\n",
    "\n",
    "def train_imshow(data):\n",
    "    classes = ('Control', 'Depressed') # Defining the classes we have\n",
    "    dataiter = iter(data)\n",
    "    images, labels = dataiter.next()\n",
    "    print(images[0].size)\n",
    "    fig, axes = plt.subplots(figsize=(10, 4), ncols=5)\n",
    "    for i in range(5):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].permute(1, 2, 0)) \n",
    "        ax.title.set_text(' '.join('%5s' % classes[labels[i]]))\n",
    "    plt.show()\n",
    "#train_imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Depress_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Depress_Net, self).__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3 ),nn.ReLU(),\n",
    "                      nn.MaxPool2d(2))\n",
    "        self.block2 = nn.Sequential(nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3 ),nn.ReLU(),\n",
    "                      nn.MaxPool2d(2))\n",
    "        self.block3 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3 ),nn.ReLU(),\n",
    "                      nn.MaxPool2d(2))\n",
    "        self.block4 = nn.Sequential(nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3 ),nn.ReLU(),\n",
    "                      nn.MaxPool2d(2))\n",
    "        self.block5 = nn.Sequential(nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3 ), nn.ReLU(),\n",
    "                      nn.MaxPool2d(2))        \n",
    "        self.block6 = nn.Sequential(nn.Linear(24*13*13, 1000), nn.Linear(1000, 2))\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.block2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.block3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.block4(x)\n",
    "        #print(x.shape)\n",
    "        x = self.block5(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.block6(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-6e19f00144dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;31m#torch.save(net.state_dict(), 'dnet.pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-6e19f00144dc>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(n_epoch)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csc311\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csc311\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Depress_Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "if torch.cuda.is_available(): # Checking if we can use GPU\n",
    "    model = net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "def train_net(n_epoch): # Training our network\n",
    "    losses = []\n",
    "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train, 0):\n",
    "            #train_imshow(train)\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            losses.append(loss)\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.10f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    plt.plot(losses, label='Training loss')\n",
    "    plt.show()\n",
    "    print('Finished Training')\n",
    "train_net(2000)   \n",
    "#torch.save(net.state_dict(), 'dnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
